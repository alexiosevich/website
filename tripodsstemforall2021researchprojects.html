<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>tripodsstemforall2021researchprojects</title>
  </head>
  <body alink="#EE0000" link="#0000EE" vlink="#551A8B" text="#000000"
    bgcolor="#999999">
    <div align="center"><font color="#ff0000"><b><font size="+3">Tripods/StemForAll2021
























            Research Projects<br>
          </font></b></font>
      <div align="left"><br>
        <br>
        <b>i) A learning theory perspective on Erdos type problems in
          combinatorial geometry</b> <br>
        <br>
        <b>Project team:</b> Alex Iosevich, Azita Mayeli, Brian McDonald
        and Emmett Wyman <br>
        <br>
        <b>Description:</b> We are going to study the connections
        between the Vapnik-Chervonenkis dimension and problems in
        combinatorial geometry, such as the Erdos distance problem, the
        Szemeredi-Trotter incidence theorem and related topics. Roughly
        speaking, one can create learning tasks and natural families of
        classifiers such that when computing the VC-dimension, one
        encounters interesting point configuration problems that shed
        considerable amount of light on the aforementioned combinatorial
        problems. <br>
        <br>
        <b>Participants:</b> Nathanel Grand and Maxwell Sun<br>
        <br>
        <br>
        <b>ii) Neural networks and universal algebras </b><br>
        <br>
        <b>Project team:</b> Charlotte Aten and Alex Iosevich <br>
        <br>
        <b>Description:</b><a href="charlottetripods21project.pdf"> .pdf
        </a><br>
        <br>
        <b>Participants:</b> Nicholas Cimaszewski, Michele Martino,
        Svetlana Pack, Conor Taliancic, and Andrey Yao <br>
        <br>
        <br>
        <b>iii) Neural networks with noise </b><br>
        <br>
        <b>Project team: </b>Alex Iosevich and Steven Senger <br>
        <br>
        <b>Description:</b> <a href="sengertripods21project.pdf">.pdf</a><br>
        <br>
        <b>Participants:</b> Jordan Darefsky, Lucy Lin, George Lyu, Anna
        Myakushina, Edmund Sepeku, Maxwell Sun <br>
        <br>
        <br>
        <b>iv) </b><b>Neural networks and sales models with economic
          indicators</b><br>
        <br>
        <b>Project team: </b>Alex Iosevich <br>
        <br>
        <b>Description:</b> Many sales models starting returning less
        than stellar results during the Covid era, in part because the
        training data came from before the Covid period. In this project
        we are going to take several publically available data sets
        containing sales data and try to come up with the right mix of
        economic (and other) indicators that will make predictions as
        stable as possible across time, including the Covid period. <br>
        <br>
        <b>Participants:</b> Nicholas O'Brien, Haiyan Huang, George Lyu,
        Kevin Xue, Kehan Yu, Kaiyuan Zhao, Stella Zhang<br>
        <br>
        <br>
        <b>v) </b><b>VC-dimension and neural networks <br>
        </b> <br>
        <b>Project team:</b> Ivan Chio, Alex Iosevich, Azita Mayeli,
        Andrew Thomas, and Emmett Wyman <br>
        <br>
        <b>Description:</b> When we go over Chapter 20 (neural
        networks), we are going to see that neural networks are
        "universal approximators" in that any Lipschitz function can be
        approximated by a neural network arbitrarily closely. This is a
        fundamental result, but many real-life data sets are not
        realistically described by a Lipschitz function because the
        Lipschitz condition limits volatility. In this project we are
        going to explore the universal approximation in the case when
        Lipschitz functions are replaced by more complicated (and
        hopefully more realistic) classes of function, such as function
        with graphs satisfying a suitable fractal dimension condition. <br>
        <br>
        <b>Participants:</b> Julie Fleischman, Filippo Iulianelli,
        Michele Martino, Svetlana Pack, Conor Taliancic, Nate Whybra,
        Kaiyuan Zhao <br>
        <br>
        <br>
        <b>vi) Natural language processing on the social web </b><br>
        <br>
        <b>Project team:</b> Alex Iosevich, Boris Iskra and Patricia
        Medina <br>
        <br>
        <b>Description:</b> The idea of this project is to extract data
        from Twitter on certain topics, doing an NPL setup and
        performing and analyzing this social media data using machine
        learning techniques such as SVM, neural networks, and dimension
        reduction methods such as PCA and auto-encoders. Tools such as
        MongoDB will come in handy, and the participants will have the
        option of learning how to work on a given database in the cloud.
        The project is inspired by the presentations in the MAA-SIAM and
        TRIPODS Advanced Workshop in Data Science for Mathematical
        Sciences Faculty (ICERM) which used code based on "mining the
        Social Web" book by Matthew A. Russel. Several sets of code will
        be provided that will dictate the different milestones of the
        project. <span style="font-family: Arial, Helvetica,
          sans-serif; font-style: normal; font-variant-ligatures:
          normal; font-variant-caps: normal; font-weight: 400;
          letter-spacing: normal; orphans: 2; text-align: start;
          text-indent: 0px; text-transform: none; white-space: normal;
          widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;
          background-color: rgb(255, 255, 255);
          text-decoration-thickness: initial; text-decoration-style:
          initial; text-decoration-color: initial; color: rgb(32, 31,
          30); font-size: 14.6667px;"></span><br>
        <br>
        <b>Participants:</b> Ivan Chio, Haiyan Huang, Zhiyu Lei, Lucy
        Lin,&nbsp; Anna Myakushina, Edmund Sepeku, Siriu Wang<br>
        <br>
        <b><br>
          vii) Hype versus performance in the English football league </b><br>
        <br>
        <b>Project team:</b> Alex Iosevich <br>
        <br>
        <b>Description:</b> We are going to scrape the web for a news
        stories on players in the English football league and come up
        with a "hype metric" by rating how positive the stories are. We
        are also going to compile a variety of performance based
        metrics. We will then run a variety of neural network models to
        check how well the "hype metric" and performance ratings
        correlate. <br>
        <br>
        <b>Participants:</b> Noah Boonin, Jordan Darefsky, Kevin Xue <br>
        <br>
        <br>
        <br>
        <br>
      </div>
    </div>
  </body>
</html>
