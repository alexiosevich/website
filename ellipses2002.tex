\documentstyle{amsppt}\tolerance 3000\pagewidth{5.5in}\vsize7.0in\magnification=\magstep1\widestnumber\key{AAAAAAAAAAAAAAA}\NoRunningHeads\topmatter\title Lattice points inside random ellipses\endtitle\author Steve Hofmann and Alex Iosevich\endauthor\thanks Research supported in part by NSF grants\endthanks\abstract Let $N_a(t)=\# \{t \Omega_a \cap {\Bbb Z}^2\}$, where$\Omega_a= \left\{x \in {\Bbb R}^2: \frac{x_1^2}{a_1}+\frac{x_2^2}{a_2} \leq 1 \right\}$. We prove that ${\left(\int_{\frac{1}{2}}^{2} \int_{\frac{1}{2}}^2 {|E_a(t)|}^2 da_1da_2\right)}^{\frac{1}{2}}\lessapprox t^{\frac{1}{2}}$, improving a corresponding $L^1$estimate recently obtained by Toth and Petridis. The proof still works if$\Omega_a$ is replaced by a suitable dilation of any convex domain with asmooth boundary and everywhere non-vanishing curvature. \endabstract\endtopmatter\head Introduction \endhead\vskip.125inLet$$ N_a(t)=\# \{t \Omega_a \cap {\Bbb Z}^2\}, \tag0.1$$ where$$ \Omega_a= \left\{x \in {\Bbb R}^2: \frac{x_1^2}{a_1}+\frac{x_2^2}{a_2} \leq 1 \right\}, \tag0.2$$ with $\frac{1}{2}\leq a_j \leq 2$.Let$$ N_a(t)=t^2 |\Omega_a|+E_a(t). \tag0.3$$It is well-known that$$ |E_a(t)| \lesssim t^{\frac{2}{3}}, \tag0.4$$where here and throughout the paper, $A \lesssim B$ means thatthere exists a positive constant $C$ such that $A \leq CB$.Similarly, $A \lessapprox B$, with a parameter $t$, means thatgiven $\delta>0$ there exists $C_{\delta}>0$ such that $A \leqC_{\delta}t^{\delta}B$.A number of improvements over $(0.4)$ have been obtained overthe years culminating in Huxley's $|E_a(t)| \lessapproxt^{\frac{46}{73}}$ estimate a few years ago. See \cite{Huxley96}and the references contained therein. However, the conjecturedresult, $|E_a(t)| \lessapprox t^{\frac{1}{2}}$ is nowhere nearresolution. In fact, it is not known if there exists a single$a=(a_1, a_2)$ such that $|E_a(t)| \lessapprox t^{\frac{1}{2}}$.The question of finding such an $a$ was posed by Sarnak a numberof years ago.Toth and Petridis (\cite{TP02}) recently proved that$$ \int_{\frac{1}{2}}^{2} \int_{\frac{1}{2}}^{2} |E_a(t)| da \lessapproxt^{\frac{1}{2}}. \tag0.5$$In this paper we prove that$$ {\left( \int_{\frac{1}{2}}^{2} \int_{\frac{1}{2}}^{2} {|E_a(t)|}^2 da\right)}^{\frac{1}{2}} \lessapprox t^{\frac{1}{2}}. \tag0.6$$Our main result is the following. \proclaim{Theorem 0.1} Let$N_a(t)$, $E_a(t)$, and $\Omega_a$ be  as above. Then $(0.6)$holds. \endproclaim \remark{Remark} The proof of Theorem 0.1 goes  without any siginificantchanges if tne ellipse $\Omega_a$ is replaced by$\{(a_1^{-\frac{1}{2}}x_1, a_2^{-\frac{1}{2}}x_2): x \in \Omega\}$, where$\Omega$ is a convex planar set with a smooth boundary and curvaturebounded from below. \endremark  Obseve that Sarnak's question would be asnwered by the followingstrengthening of $(0.6)$. \proclaim{Conjecture 0.2}  Given any $\delta>0$,$$ \sup_{t \ge 1} t^{-\frac{1}{2}-\delta}|E_{(\cdot)}(t)| \in L^p\left(\left[\frac{1}{2},2 \right] \times \left[\frac{1}{2},2 \right]\right), \tag0.7$$ for some $p \ge 1$ with a constant depending on$\delta$. \endproclaim In fact, $(0.7)$ would, of course, imply that the estimate $|E_a(t)|\lessapprox t^{\frac{1}{2}}$ holds for almost every $a \in \left(\left[\frac{1}{2},2 \right] \times \left[\frac{1}{2},2 \right]\right)$. We hope to address this issue in a subsequent paper. Other types of square averages of lattice point discrepancy functionshave been studied in the past and in recent years. For example, aclassical result due to Kendall says that $$ \int_{{\Bbb T}^2} {|\# \{(t \Omega +\tau) \cap {\BbbZ}^2\}-t^2|\Omega||}^2 d\tau \lesssim t^{\frac{1}{2}}, \tag0.8$$for every convex planar domain whose boundary has everywherenon-vanishing Gaussian curvature. Another type of average is studied in \cite{ISS02}. The authors provethat $$ {\left( \frac{1}{h} \int_R^{R+h} {|\# \{t \Omega \cap {\BbbZ}^2\}-t^2|\Omega||}^2 dt \right)}^{\frac{1}{2}} \lesssim R^{\frac{1}{2}}\tag0.9$$ with $h \gtrsim \log(R)$ provided that $\Omega$ is convex andhas a smooth boundary with everywhere non-vanishing Gaussian curvature.Similar results are known in higher dimensions, but we do not addressthis issue here. See, for example, \cite{Huxley96} and \cite{ISS02} andreferences contained therein. The proof of $(0.8)$ uses only the decay of the Fourier transform of thecharacteristic function of $\Omega$. The proof of $(0.9)$ uses not onlythe decay, but also the asymptotic formula for $\widehat{\chi}_{\Omega}$and the structure of $\Omega^{*}$, the convex body dual to $\Omega$. Theproof of $(0.6)$ given in the proof of Theorem 0.1 requires, in addition,a precise analysis of an oscillatory integral which arises from theasymptotic formula for $\widehat{\chi}_{\Omega}$ and integration withrespect to the accentricities. \vskip.125in \head Proof of Theorem 0.1 \endhead \vskip.125inWestart with the following standard reduction. Let $\rho \in C^{\infty}_0\left( \frac{1}{4}, 4\right)$ such that $\rho \equiv 1$ on $[1,2]$ and$\int \rho(x) dx=1$. Let$\rho_{\epsilon}(x)=\epsilon^{-2} \rho \left( \frac{x}{\epsilon} \right)$.Let$$ N_a^{\epsilon}(t)=\sum_{k \in {\Bbb Z}^2} \chi_{t\Omega_a}*\rho_{\epsilon}(k)=t^2|\Omega_a|+t^2 \sum_{k \not=(0,0)}\widehat{\chi}_{\Omega_a}(tk) \widehat{\rho}(\epsilon k)=t^2|\Omega_a|+E_a^{\epsilon}(t). \tag1.1$$It is not hard to see that there exists $C>0$ such that$$ N_a^{\epsilon}(t-C\epsilon) \leq N_a(t) \leqN_a^{\epsilon}(t+C\epsilon). \tag1.2$$It follows that$$ |E_a(t)| \lesssim |E_a^{\epsilon}(t)|+t \epsilon. \tag1.3$$We conclude that it suffices to establish estimates for$E_a^{\epsilon}(t)$ with$\epsilon=t^{-\frac{1}{2}}$.Using  the standard asymptotic formula for the Fourier transformof the characteristic function of a bounded smooth convex domainwhere the Gaussian curvature of the boundary is non-vanishing,(see e.g \cite{Hertz60}), we see that$\widehat{\chi}_{\Omega_a}(tk)$ is a sum of two terms of theform$$ e^{2 \pi i t {|k|}_a} \ t^{-\frac{3}{2}} {|k|}_a^{-\frac{3}{2}}+O({(t|k|)}^{-\frac{5}{2}}), \tag1.4$$ where$$ {|k|}_a=\sqrt{a_1 k_1^2+a_2 k_2^2}. \tag1.5$$It follows that$$ E^{\epsilon}_a(t)=t^{\frac{1}{2}} \sum_{k \not=(0,0)} e^{2 \pi it{|k|}_a} {|k|}_a^{-\frac{3}{2}}\widehat{\rho}(\epsilonk)\widehat{\rho}(\epsilon l)+t^2\sum_{k \not=(0,0)} {(t{|k|}_a)}^{-\frac{5}{2}}=I+II. \tag1.6$$Since we can easily handle $II$ point-wise, we turn ourattention to $I$.  Squaring, integrating in $a$, and replacingthe limits of integration in $a$ by a smooth cutoff function, weget$$ t \sum_{k,l \not=(0,0)} {|k|}^{-\frac{3}{2}} {|l|}^{-\frac{3}{2}}\widehat{\rho}(\epsilon k) \widehat{\rho}(\epsilon l) \int e^{2\pi i t({|k|}_a-{|l|}_a)} \psi_{k,l}(a) da, \tag1.7$$ where$$\psi_{k,l}(a)={\left( \frac{|k|}{{|k|}_a}\right)}^{\frac{3}{2}}{\left( \frac{|l|}{{|l|}_a}\right)}^{\frac{3}{2}} \psi(a).\tag1.8$$Observe that when $k \not=(0,0)$ and $l \not=(0,0)$, $\psi_{k,l}\inC_0^{\infty}$ with constants uniform in $k$ and $l$. It suffices to showthat this expression is bounded above$C_{\delta} t^{\delta}$ for any $\delta>0$. Consider$$ I_{k,l}(t)=\int e^{2 \pi i t({|k|}_a-{|l|}_a)} \psi_{k,l}(a) da.\tag1.9$$Let $\Phi_{k,l}(a)={|k|}_a-{|l|}_a$. A calculation shows that$$ \det H\Phi_{k,l}(a)=-\frac{1}{16}\frac{{(k_1^2l_2^2-l_1^2k_2^2)}^2}{{|k|}_a^3 {|l|}_a^3}.\tag1.10$$\head Non-zero determinant \endhead\vskip.125inWe first consider the case $|\frac{k_1}{k_2}|\not=|\frac{l_1}{l_2}|$, $|k_j|, |l_j| \ge 1$. Let $\delta$ be asmall positive number. Since$$|\widehat{\rho}(\epsilon k)| \leq C_N {(1+|\epsilon k|)}^{-N},\tag2.1$$ and $|I_{k,l}(t)| \lesssim 1$, it follows that$$ t \sum_{|k_j|,|l_j| \ge\epsilon^{-1-\delta}}{|k|}^{-\frac{3}{2}} {|l|}^{-\frac{3}{2}}\widehat{\rho}(\epsilon k)\widehat{\rho}(\epsilon l)I_{k,l}(t)\lesssim t \tag2.2$$ as seen by choosing $N \approx\frac{2}{\delta}$.We now consider$$ t \sum_{|k_j|,|l_j| \leq\epsilon^{-1-\delta}; |\frac{k_1}{k_2}|\not=|\frac{l_1}{l_2}|}{|k|}^{-\frac{3}{2}} {|l|}^{-\frac{3}{2}}\widehat{\rho}(\epsilon k)\widehat{\rho}(\epsilon l)I_{k,l}(t).\tag2.3$$Using the method of stationary phase, (see e.g. \cite{Stein93} and theappendix below) the right hand side of $(2.3)$ is bounded by$$ \sum_{|k_j|,|l_j| \leq\epsilon^{-1-\delta}; |\frac{k_1}{k_2}| \not=|\frac{l_1}{l_2}|}\frac{1}{|k_1^2l_2^2-l_1^2k_2^2|}=\sum_{|k_j|,|l_j| \leq\epsilon^{-1-\delta}; |\frac{k_1}{k_2}| \not=|\frac{l_1}{l_2}|}\frac{1}{|k_1l_2-l_1k_2||k_1l_2+l_1k_2|}. \tag2.4$$Either $sgn(k_1l_2)=sgn(l_1k_2)$ or $sgn(k_1l_2)=-sgn(l_1k_2)$.In either case, the expression $(2.4)$ is bounded by theexpression of the form$$ \epsilon^{-2-2\delta} \sum_{|k_1|,|l_2| \leq\epsilon^{-1-\delta}} \frac{1}{k_1} \frac{1}{l_2} \lessapprox t\tag2.5$$ since $\epsilon=t^{-\frac{1}{2}}$.We now deal with the case when one of $k_1,k_2,l_1,l_2$ is $0$.Using $(1.10)$ with, say, $k_2=0$, we see that$$ |I_{k,l}(t)| \lesssim t^{-1}k_1^{-2}l_2^{-2}. \tag2.6$$Using $(2.6)$ we get, in view of $(2.2)$, with $k_2=0$,$$ \sum_{\epsilon^{-1-\delta} \ge |k_1|, |l_1|, |l_2| \ge 1}k_1^{-2} l_2^{-2} \lesssim t^{\frac{1}{2}}. \tag2.7$$If more than one of $|k_1|$, $|k_2|$, $|l_1|$, $|l_2|$, theestimate is even easier as we shall see below.\head Zero determinant \endhead\vskip.125inWe now handle the case where $\frac{k_1}{k_2}= \pm\frac{l_1}{l_2}$. In this case, if $k_1=0$, then $l_1=0$.Similarly, if $k_2=0$, then $l_2=0$. Estimating $I_{k,l}(t)$trivially by $1$, we get$$ t \sum_{|k_1|, |l_1| \ge 1} {|k_1|}^{-\frac{3}{2}}{|l_1|}^{-\frac{3}{2}}{(1+\epsilon|k_1|)}^{-N}{(1+\epsilon|l_1|)}^{-N} \lesssim t,\tag3.1$$ and similarly if $k_1=l_1=0$.Thus we may assume that $|k_j| \ge 1$ and $|l_j| \ge 1$. Let$\Phi_{k,l}(a)={|k|}_a-{|l|}_a$. Differentiating and using thefact that $|\frac{k_1}{k_2}|=|\frac{l_1}{l_2}|$, we have$$ \frac{\partial^2 \Phi}{\partiala_1^2}=-\frac{1}{4}\left(\frac{k_1^4}{{|k|}_a^3}-\frac{l_1^4}{{|l|}_a^3}\right)=-\frac{1}{4} \frac{k_1^4}{{|k|}_a^3}\left(\frac{|k_2|-|l_2|}{|k_2|} \right), \tag3.2$$ and$$ \frac{\partial^2 \Phi}{\partiala_2^2}=-\frac{1}{4} \left(\frac{k_2^4}{{|k|}_a^3}-\frac{l_2^4}{{|l|}_a^3}\right)=-\frac{1}{4} \frac{k_2^4}{{|k|}_a^3}\left(\frac{|k_1|-|l_1|}{|k_1|} \right). \tag3.3$$In the regime $|k_j|=|l_j|$, the estimate follows trivially. Wejust dominate $I_{k,l}(t)$ by a constant and end up with$$ t \sum_{|k_j| \ge 1} {|k|}^{-3} \lesssim t. \tag3.4$$If $|k_j| \not=|l_j|$, then either $||k_1|-|l_1|| \ge 1$ or$||k_2|-|l_2|| \ge 1$. In the former case we use van der Corputlemma (see e.g. \cite{Stein93} and the appendix below) with $(3.3)$, andin the latter case with $(3.2)$. The two cases are the same, so weconsider the former without loss of generality. Taking $(2.2)$ intoaccount, we end up with$$ t \times t^{-\frac{1}{2}} \sum_{1 \leq |k_j|, |l_1| \leq\epsilon^{-1-\delta}; ||k_1|-|l_1|| \ge 1} {|k|}^{-\frac{3}{2}}{|l|}^{-\frac{3}{2}} {|k|}^{\frac{3}{2}} {|k_1|}^{\frac{1}{2}}{|k_2|}^{-2}{||k_1|-|l_1||}^{-\frac{1}{2}}$$ $$=t^{\frac{1}{2}}\sum_{1 \leq |k_j|, |l_1| \leq \epsilon^{-1-\delta};||k_1|-|l_1|| \ge 1} {|l_1|}^{-\frac{3}{2}}{|k_1|}^{\frac{1}{2}}{|k_2|}^{-2}{||k_1|-|l_1||}^{-\frac{1}{2}}$$$$ \lessapprox t^{\frac{1}{2}} \epsilon^{-\frac{1}{2}}\sum_{1 \leq |k_1|, |l_1| \leq \epsilon^{-1-\delta};||k_1|-|l_1|| \ge 1}{|l_1|}^{-\frac{3}{2}}{||k_1|-|l_1||}^{-\frac{1}{2}} \lessapproxt. \tag3.5$$This completes the proof of Theorem 0.1.\vskip.125in \head Appendix: Oscillatory integrals of the first kind \endhead \vskip.125in In this paper we made use of the following basic facts about theoscillatory integrals of the form $$ I(t)=\int_{{\Bbb R}^d} e^{i t f(x)} \psi(x) dx, \tag4.1$$ where$\psi$ is a smooth cutoff function and $f$ is smooth. The proofs can befound in many books. See, for example \cite{Stein93}. \proclaim{Theorem 4.1} Suppose that $f$ is convex and $\det(D^2f) \gec_0>0$, where $D^2f$ denotes the Hessian matrix of $f$. Then $$ |I(t)| \lesssim t^{-\frac{d}{2}} c_0^{-\frac{1}{2}}. \tag4.2$$\endproclaim \proclaim{Theorem 4.2} Suppose that $|\frac{\partial^2 f}{\partialx_j^2}| \ge c_0$. Then $$ |I(t)| \lesssim t^{-\frac{1}{2}} c_0^{-\frac{1}{2}}. \tag4.3$$ \endproclaim We note that in both theorems the constants may depend on the upperbounds of derivatives of $f$. \newpage\head References \endhead\vskip.125in\ref \key Huxley96 \by M. N. Huxley \book Area, Lattice Points,and Exponentials Sums \yr 1996 \bookinfo London MathematicalSociety Monographs New Series 13 \publ Oxford Univ. Press\endref\ref \key ISS02 \by A. Iosevich, E. Sawyer, and A. Seeger \paper Meansquare discrepancy bounds for the number of lattice points in largeconvex bodies \jour Journal D'Analyse, Tom Wolff Memorial Issue (toappear) \yr 2002 \endref \ref \key Stein93 \by E. M. Stein \book Harmonic Analysis \yr1993 \publ Princeton University Press \endref\ref \key TP02 \by J. Toth and Y. Petridis \paper \jour(preprint) \yr 2002 \endref\enddocument
